{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Comparison\n",
    "\n",
    "In diesem Notebook wird die Performance der drei Modelle miteinander verglichen, um anschliessend das beste Modelle für die Anwendung auszuwählen."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Modelle und Daten laden\n",
    "\n",
    "Zuerst werden die trainierten Modelle und der bereinigte Datensatz geladen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from joblib import load\n",
    "from data_loader import load_data\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Modelle laden\n",
    "rf = load(\"../Models/random_forest_model.joblib\")\n",
    "gd = load(\"../Models/gradient_boosting_model.joblib\")\n",
    "lr = load(\"../Models/linear_regression_model.joblib\")\n",
    "\n",
    "# Lade den bereinigten Datensatz\n",
    "df = pd.read_csv(\"../data/life_expectancy_cleaned.csv\")\n",
    "\n",
    "\n",
    "# Daten laden\n",
    "X_train, X_test, y_train, y_test = load_data()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Root Mean Squared Error (RMSE) und R^2\n",
    "Um eine Model Comparison durchzuführen, schauen wir uns zwei Hauptmetriken an: Root Mean Squared Error (RMSE) und R^2.\n",
    "\n",
    "- RMSE: Diese Metrik gibt uns den durchschnittlichen Fehler, den unser Modell macht. Eine niedrigere RMSE bedeutet, dass unser Modell im Durchschnitt weniger Fehler macht, was gut ist.\n",
    "- R^2: Diese Metrik gibt uns eine Vorstellung davon, wie viel der Variation in den Daten durch unser Modell erklärt wird. Ein höherer R^2-Wert (näher an 1) bedeutet, dass unser Modell einen größeren Anteil der Variation erklärt, was ebenfalls gut ist.\n",
    "\n",
    "Ein idealer Algorithmus hätte also eine niedrige RMSE und einen hohen R^2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Model          RMSE     R-Squared\n",
      "0      Random Forest  3.094892e-02  9.692944e-01\n",
      "2  Gradient Boosting  4.002273e-02  9.486501e-01\n",
      "1  Linear Regression  6.711573e+10 -1.444026e+23\n"
     ]
    }
   ],
   "source": [
    "# Gradient Boosting Metriken berechnen\n",
    "gd_preds = gd.predict(X_test)\n",
    "gd_rmse = mean_squared_error(y_test, gd_preds, squared=False)\n",
    "gd_r2 = gd.score(X_test, y_test)\n",
    "\n",
    "# Lineare Regression Metriken berechnen\n",
    "lr_preds = lr.predict(X_test)\n",
    "lr_rmse = mean_squared_error(y_test, lr_preds, squared=False)\n",
    "lr_r2 = lr.score(X_test, y_test)\n",
    "\n",
    "# Random Forest Metriken berechnen\n",
    "rf_preds = rf.predict(X_test)\n",
    "rf_rmse = mean_squared_error(y_test, rf_preds, squared=False)\n",
    "rf_r2 = rf.score(X_test, y_test)\n",
    "\n",
    "# Zunächst erstellen wir eine leere DataFrame, um die Metriken zu speichern\n",
    "model_comparison = pd.DataFrame({\n",
    "    'Model': ['Random Forest', 'Linear Regression', 'Gradient Boosting'],\n",
    "    'RMSE': [rf_rmse, lr_rmse, gd_rmse],\n",
    "    'R-Squared': [rf_r2, lr_r2, gd_r2]\n",
    "})\n",
    "\n",
    "# Sortieren nach RMSE\n",
    "model_comparison.sort_values('RMSE', ascending=True, inplace=True)\n",
    "\n",
    "print(model_comparison)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Cross Validation and Mean Absoulte Error\n",
    "\n",
    "Um eine noch umfassendere Bewertung der Modelle zu ermöglichen, können wir zusätzliche Metriken und Techniken einsetzen. Eine davon ist die Kreuzvalidierung (Cross-Validation), bei der das Datenset in k Gruppen oder \"Folds\" aufgeteilt wird. Das Modell wird dann k Mal trainiert und getestet, wobei in jeder Runde eine andere Gruppe als Testset und die restlichen Gruppen als Trainingssatz verwendet werden. Diese Technik gibt uns eine robustere Einschätzung der Modellleistung, da sie das Modell auf verschiedenen Teilen des Datensatzes testet.\n",
    "\n",
    "Außerdem können wir den durchschnittlichen absoluten Fehler (Mean Absolute Error - MAE) betrachten, der den durchschnittlichen absoluten Unterschied zwischen den tatsächlichen und den vorhergesagten Werten misst."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dinopelesevic/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/dinopelesevic/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/dinopelesevic/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/dinopelesevic/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/dinopelesevic/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/dinopelesevic/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_gb.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/dinopelesevic/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_gb.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/dinopelesevic/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_gb.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/dinopelesevic/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_gb.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/dinopelesevic/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_gb.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Model          RMSE     R-Squared  Cross Val Score (mean)  \\\n",
      "0      Random Forest  3.094892e-02  9.692944e-01            9.216048e-01   \n",
      "2  Gradient Boosting  4.002273e-02  9.486501e-01           -4.496573e+24   \n",
      "1  Linear Regression  6.711573e+10 -1.444026e+23            9.164013e-01   \n",
      "\n",
      "            MAE  \n",
      "0  1.975505e-02  \n",
      "2  2.767806e+09  \n",
      "1  2.950472e-02  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Kreuzvalidierung und MAE für Random Forest\n",
    "rf_cv_scores = cross_val_score(rf, X_test, y_test, cv=5)\n",
    "rf_mae = mean_absolute_error(y_test, rf_preds)\n",
    "\n",
    "# Kreuzvalidierung und MAE für Linear Regression\n",
    "lr_cv_scores = cross_val_score(lr, X_test, y_test, cv=5)\n",
    "lr_mae = mean_absolute_error(y_test, lr_preds)\n",
    "\n",
    "# Kreuzvalidierung und MAE für Gradient Boosting\n",
    "gb_cv_scores = cross_val_score(gd, X_test, y_test, cv=5)\n",
    "gb_mae = mean_absolute_error(y_test, gd_preds)\n",
    "\n",
    "# Füge die neuen Metriken zur Vergleichstabelle hinzu\n",
    "model_comparison['Cross Val Score (mean)'] = [rf_cv_scores.mean(), lr_cv_scores.mean(), gb_cv_scores.mean()]\n",
    "model_comparison['MAE'] = [rf_mae, lr_mae, gb_mae]\n",
    "\n",
    "print(model_comparison)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Mean Squared Logarithmic Error, Median Absolute Error & Explained Variance Score\n",
    "Als nächstes verwenden wir noch einige weitere Metriken, um die Modelle miteinander zu vergleichen:\n",
    "\n",
    "- Mean Squared Logarithmic Error (MSLE): Diese Metrik ist besonders nützlich, wenn exponentielle Wachstumsprozesse vorhergesagt werden sollen. Sie ist weniger empfindlich gegenüber großen Fehlern und legt mehr Gewicht auf kleine Fehler.\n",
    "- Median Absolute Error: Diese Metrik ähnelt dem Mean Absolute Error, aber anstatt den Durchschnitt der absoluten Fehler zu berechnen, nimmt sie den Median. Das macht sie robuster gegenüber Ausreißern.\n",
    "- Explained Variance Score: Diese Metrik misst den Anteil der Varianz, der durch das Modell erklärt wird. Eine Punktzahl von 1.0 zeigt an, dass das Modell perfekt die Zielvariable vorhersagt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Model          RMSE     R-Squared  Cross Val Score (mean)  \\\n",
      "0      Random Forest  3.094892e-02  9.692944e-01            9.216048e-01   \n",
      "2  Gradient Boosting  4.002273e-02  9.486501e-01           -4.496573e+24   \n",
      "1  Linear Regression  6.711573e+10 -1.444026e+23            9.164013e-01   \n",
      "\n",
      "            MAE     RMSLE  Median AE  Explained Variance Score  \n",
      "0  1.975505e-02  0.019816   0.011812              9.694658e-01  \n",
      "2  2.767806e+09  1.139756   0.014524             -1.441570e+23  \n",
      "1  2.950472e-02  0.025537   0.022536              9.486780e-01  \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_log_error, median_absolute_error, explained_variance_score\n",
    "\n",
    "# Funktion, um die Wurzel des MSLE zu berechnen\n",
    "def rmsle(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
    "\n",
    "# RMSLE, Median Absolute Error und Explained Variance Score für Random Forest\n",
    "rf_rmsle = rmsle(y_test, rf_preds)\n",
    "rf_medae = median_absolute_error(y_test, rf_preds)\n",
    "rf_evs = explained_variance_score(y_test, rf_preds)\n",
    "\n",
    "# RMSLE, Median Absolute Error und Explained Variance Score für Linear Regression\n",
    "lr_rmsle = rmsle(y_test, lr_preds)\n",
    "lr_medae = median_absolute_error(y_test, lr_preds)\n",
    "lr_evs = explained_variance_score(y_test, lr_preds)\n",
    "\n",
    "# RMSLE, Median Absolute Error und Explained Variance Score für Gradient Boosting\n",
    "gb_rmsle = rmsle(y_test, gd_preds)\n",
    "gb_medae = median_absolute_error(y_test, gd_preds)\n",
    "gb_evs = explained_variance_score(y_test, gd_preds)\n",
    "\n",
    "# Füge die neuen Metriken zur Vergleichstabelle hinzu\n",
    "model_comparison['RMSLE'] = [rf_rmsle, lr_rmsle, gb_rmsle]\n",
    "model_comparison['Median AE'] = [rf_medae, lr_medae, gb_medae]\n",
    "model_comparison['Explained Variance Score'] = [rf_evs, lr_evs, gb_evs]\n",
    "\n",
    "print(model_comparison)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Mean Absolute Percentage Error & R^2 adjusted\n",
    "Zuletzt wollen wir noch den Mean Absolute Percentage Error und den R^2 adjusted berechnen. \n",
    "\n",
    "- Mean Absolute Percentage Error (MAPE): Diese Metrik gibt den durchschnittlichen prozentualen Fehler in Bezug auf die tatsächlichen Werte an. Sie ist besonders nützlich, wenn du die Fehler relativ zu den tatsächlichen Werten betrachten möchtest.\n",
    "- R^2 adjusted: Diese Metrik passt den R^2-Wert an die Anzahl der Prädiktoren in dem Modell an. Dies ist besonders nützlich, wenn du Modelle mit unterschiedlicher Anzahl von Prädiktoren vergleichst.\n",
    "\n",
    "Davor muss aber noch die Länge der Testdaten und Vorhersagen gleich sein:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(588,)\n",
      "(588,)\n",
      "(588,)\n"
     ]
    }
   ],
   "source": [
    "#Länge der Testdaten und der Vorhersagen vergleichen\n",
    "print(y_test.shape)\n",
    "print(rf_preds.shape)\n",
    "\n",
    "# y_test in ein Array umwandeln\n",
    "y_test = y_test.squeeze()\n",
    "\n",
    "# Länge der Testdaten und der Vorhersagen vergleichen\n",
    "print(y_test.shape)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anschliessend können Mean Absolute Percentage Error und R^2 adjusted berechnet werden:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Model          RMSE     R-Squared  Cross Val Score (mean)  \\\n",
      "0      Random Forest  3.094892e-02  9.692944e-01            9.216048e-01   \n",
      "2  Gradient Boosting  4.002273e-02  9.486501e-01           -4.496573e+24   \n",
      "1  Linear Regression  6.711573e+10 -1.444026e+23            9.164013e-01   \n",
      "\n",
      "            MAE     RMSLE  Median AE  Explained Variance Score          MAPE  \\\n",
      "0  1.975505e-02  0.019816   0.011812              9.694658e-01  3.820506e+00   \n",
      "2  2.767806e+09  1.139756   0.014524             -1.441570e+23  4.430180e+11   \n",
      "1  2.950472e-02  0.025537   0.022536              9.486780e-01  5.583414e+00   \n",
      "\n",
      "   R-Squared Adjusted  \n",
      "0        9.519355e-01  \n",
      "2       -2.260382e+23  \n",
      "1        9.196202e-01  \n"
     ]
    }
   ],
   "source": [
    "# Funktion zur Berechnung des MAPE\n",
    "def mape(y_true, y_pred):\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "# Funktion zur Berechnung des R^2 adjusted\n",
    "def r2_adjusted(r2, n, p):\n",
    "    return 1 - (1 - r2) * (n - 1) / (n - p - 1)\n",
    "\n",
    "# MAPE und R^2 adjusted für Random Forest\n",
    "rf_mape = mape(y_test, rf_preds)\n",
    "rf_r2_adj = r2_adjusted(rf_r2, len(y_test), X_test.shape[1])\n",
    "\n",
    "# MAPE und R^2 adjusted für Linear Regression\n",
    "lr_mape = mape(y_test, lr_preds)\n",
    "lr_r2_adj = r2_adjusted(lr_r2, len(y_test), X_test.shape[1])\n",
    "\n",
    "# MAPE und R^2 adjusted für Gradient Boosting\n",
    "gb_mape = mape(y_test, gd_preds)\n",
    "gb_r2_adj = r2_adjusted(gd_r2, len(y_test), X_test.shape[1])\n",
    "\n",
    "# Füge die neuen Metriken zur Vergleichstabelle hinzu\n",
    "model_comparison['MAPE'] = [rf_mape, lr_mape, gb_mape]\n",
    "model_comparison['R-Squared Adjusted'] = [rf_r2_adj, lr_r2_adj, gb_r2_adj]\n",
    "\n",
    "print(model_comparison)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Modellwahl und Fazit"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In diesem Kapitel wollen wir die Resultat der Model Comparison analysieren. Beginnen wir dafür mit den Resultaten des Random Forest Modells:\n",
    "\n",
    "### 6.1 Random Forest: \n",
    "\n",
    "- **RMSE**:                      3.094892e-02. Das bedeutet, dass das Modell im Durchschnitt eine Abweichung von etwa 3.1% vom tatsächlichen Wert hat. Dies ist ein ziemlich guter Wert und deutet auf eine hohe Genauigkeit des Modells hin.\n",
    "\n",
    "- **R-Squared**:                 9.692944e-01 (96.93%). Dies bedeutet, dass 96.93% der Variationen in den Daten durch das Modell erklärt werden können. Dies ist ein ausgezeichneter Wert.\n",
    "\n",
    "- **Cross Val Score (mean)**:    9.216048e-01 (92.16%). Dies deutet darauf hin, dass das Modell konstant hohe Genauigkeiten über verschiedene Aufteilungen der Trainingsdaten liefert.\n",
    "\n",
    "- **MAE**:                       1.975505e-02 (1.98%). Dies deutet darauf hin, dass das Modell im Durchschnitt etwa 1.98% vom tatsächlichen Wert entfernt liegt. Dies ist ebenfalls ein sehr guter Wert.\n",
    "\n",
    "- **RMSLE**:                     0.019816. Dies ist der Logarithmische Mittlere Quadratische Fehler. Je näher dieser Wert an 0 ist, desto besser das Modell.\n",
    "\n",
    "- **Median AE**:                 0.011812. Dies ist der mediane absolute Fehler. Ein niedrigerer Wert ist besser.\n",
    "\n",
    "- **Explained Variance Score**:  9.694658e-01 (96.95%). Dies ist ein weiteres Maß dafür, wie gut das Modell die Variationen in den Daten erklärt.\n",
    "\n",
    "- **MAPE**                       3.820506e+00 (3.82%). Dies ist der mittlere absolute prozentuale Fehler. Ein niedrigerer Wert ist besser.\n",
    "\n",
    "- **R-Squared Adjusted**:        9.519355e-01 (95.19%). Dies ist ein bereinigtes R-Squared, das die Anzahl der Prädiktoren im Modell berücksichtigt."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir sehen also, dass die Werte des Random Forest durchaus sinnvoll sind und das Modell gut performen sollte. Der Wert des R^2 ist zwar ein ausgezeichneter Wert, allerdings sind solche Werte immer mit Vorsicht zu geniessen. Ein hoher R^2-Wert kann auch ein Anzeichen für Überanpassung sein, insbesondere wenn das Modell eine große Anzahl von Features hat. In solchen Fällen könnte das Modell die Trainingsdaten \"zu gut\" lernen und möglicherweise schlecht auf neue, bisher ungesehene Daten reagieren.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Gradient Boosting\n",
    "\n",
    "Der Gradient Boosting hat eine negative Cross-Validation-Score und eine sehr große MAE, RMSLE und MAPE. Dies könnte auf ein Overfitting des Modells hinweisen, oder dass das Modell Schwierigkeiten hat, die Komplexität der Daten anzupassen.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Linear Regression:\n",
    "\n",
    "Die lineare Regression hat ein negatives R-Squared und einen sehr hohen RMSE. Dies könnte darauf hindeuten, dass das Modell Schwierigkeiten hat, die Daten anzupassen, oder dass es starke Nichtlinearitäten in den Daten gibt, die das Modell nicht berücksichtigt."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fazit\n",
    "\n",
    "Auf Grundlage dieser Ergebnisse scheint das **Random Forest-Modell** die beste Leistung zu haben. Es hat die höchsten Werte für R-Squared und Cross Validation Score und die niedrigsten Fehlerwerte. Es scheint auch, dass es am besten in der Lage ist, die Variationen in den Daten zu erklären.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
